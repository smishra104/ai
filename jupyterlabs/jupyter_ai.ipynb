{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9675f7b9-5584-4506-95af-589b2d3230f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv(), override=True)\n",
    "openai.api_key = os.getenv('OPEN_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a7669c7-1e1a-4331-856f-5c76062e1e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did Yoda count to five?\n",
      "\n",
      "Because there is no try, only do or do not!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-4o',\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': 'You avoid dad jokes.'},\n",
    "        {'role': 'user', 'content': 'Write a yoda joke'}\n",
    "    ]\n",
    ")\n",
    "for c in response.choices:\n",
    "    print(c.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61e11bc9-0180-4697-9429-a53a2f77a288",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai_magics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bb03b31-eb5a-40d5-8fb4-8df1b165e7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Provider | Environment variable | Set? | Models |\n",
       "|----------|----------------------|------|--------|\n",
       "| `ai21` | `AI21_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`ai21:j1-large`</li><li>`ai21:j1-grande`</li><li>`ai21:j1-jumbo`</li><li>`ai21:j1-grande-instruct`</li><li>`ai21:j2-large`</li><li>`ai21:j2-grande`</li><li>`ai21:j2-jumbo`</li><li>`ai21:j2-grande-instruct`</li><li>`ai21:j2-jumbo-instruct`</li></ul> |\n",
       "| `bedrock` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock:amazon.titan-text-express-v1`</li><li>`bedrock:amazon.titan-text-lite-v1`</li><li>`bedrock:amazon.titan-text-premier-v1:0`</li><li>`bedrock:ai21.j2-ultra-v1`</li><li>`bedrock:ai21.j2-mid-v1`</li><li>`bedrock:ai21.jamba-instruct-v1:0`</li><li>`bedrock:cohere.command-light-text-v14`</li><li>`bedrock:cohere.command-text-v14`</li><li>`bedrock:cohere.command-r-v1:0`</li><li>`bedrock:cohere.command-r-plus-v1:0`</li><li>`bedrock:meta.llama2-13b-chat-v1`</li><li>`bedrock:meta.llama2-70b-chat-v1`</li><li>`bedrock:meta.llama3-8b-instruct-v1:0`</li><li>`bedrock:meta.llama3-70b-instruct-v1:0`</li><li>`bedrock:meta.llama3-1-8b-instruct-v1:0`</li><li>`bedrock:meta.llama3-1-70b-instruct-v1:0`</li><li>`bedrock:meta.llama3-1-405b-instruct-v1:0`</li><li>`bedrock:mistral.mistral-7b-instruct-v0:2`</li><li>`bedrock:mistral.mixtral-8x7b-instruct-v0:1`</li><li>`bedrock:mistral.mistral-large-2402-v1:0`</li><li>`bedrock:mistral.mistral-large-2407-v1:0`</li></ul> |\n",
       "| `bedrock-chat` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`bedrock-chat:amazon.titan-text-express-v1`</li><li>`bedrock-chat:amazon.titan-text-lite-v1`</li><li>`bedrock-chat:amazon.titan-text-premier-v1:0`</li><li>`bedrock-chat:anthropic.claude-v2`</li><li>`bedrock-chat:anthropic.claude-v2:1`</li><li>`bedrock-chat:anthropic.claude-instant-v1`</li><li>`bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-haiku-20240307-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-opus-20240229-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-5-haiku-20241022-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-5-sonnet-20240620-v1:0`</li><li>`bedrock-chat:anthropic.claude-3-5-sonnet-20241022-v2:0`</li><li>`bedrock-chat:meta.llama2-13b-chat-v1`</li><li>`bedrock-chat:meta.llama2-70b-chat-v1`</li><li>`bedrock-chat:meta.llama3-8b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-70b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-1-8b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-1-70b-instruct-v1:0`</li><li>`bedrock-chat:meta.llama3-1-405b-instruct-v1:0`</li><li>`bedrock-chat:mistral.mistral-7b-instruct-v0:2`</li><li>`bedrock-chat:mistral.mixtral-8x7b-instruct-v0:1`</li><li>`bedrock-chat:mistral.mistral-large-2402-v1:0`</li><li>`bedrock-chat:mistral.mistral-large-2407-v1:0`</li></ul> |\n",
       "| `bedrock-custom` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify the ARN (Amazon Resource Name) of the custom/provisioned model as the model ID. For more information, see the [Amazon Bedrock model IDs documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html).\n",
       "\n",
       "The model provider must also be specified below. This is the provider of your foundation model *in lowercase*, e.g. `amazon`, `anthropic`, `meta`, or `mistral`. |\n",
       "| `anthropic-chat` | `ANTHROPIC_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`anthropic-chat:claude-2.0`</li><li>`anthropic-chat:claude-2.1`</li><li>`anthropic-chat:claude-3-opus-20240229`</li><li>`anthropic-chat:claude-3-sonnet-20240229`</li><li>`anthropic-chat:claude-3-haiku-20240307`</li><li>`anthropic-chat:claude-3-5-haiku-20241022`</li><li>`anthropic-chat:claude-3-5-sonnet-20240620`</li><li>`anthropic-chat:claude-3-5-sonnet-20241022`</li></ul> |\n",
       "| `azure-chat-openai` | `AZURE_OPENAI_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | This provider does not define a list of models. |\n",
       "| `cohere` | `COHERE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`cohere:command`</li><li>`cohere:command-nightly`</li><li>`cohere:command-light`</li><li>`cohere:command-light-nightly`</li><li>`cohere:command-r-plus`</li><li>`cohere:command-r`</li></ul> |\n",
       "| `gemini` | `GOOGLE_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`gemini:gemini-1.5-pro`</li><li>`gemini:gemini-1.5-flash`</li><li>`gemini:gemini-1.0-pro`</li><li>`gemini:gemini-1.0-pro-001`</li><li>`gemini:gemini-1.0-pro-latest`</li><li>`gemini:gemini-1.0-pro-vision-latest`</li><li>`gemini:gemini-pro`</li><li>`gemini:gemini-pro-vision`</li></ul> |\n",
       "| `gpt4all` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | <ul><li>`gpt4all:ggml-gpt4all-j-v1.2-jazzy`</li><li>`gpt4all:ggml-gpt4all-j-v1.3-groovy`</li><li>`gpt4all:ggml-gpt4all-l13b-snoozy`</li><li>`gpt4all:mistral-7b-openorca.Q4_0`</li><li>`gpt4all:mistral-7b-instruct-v0.1.Q4_0`</li><li>`gpt4all:gpt4all-falcon-q4_0`</li><li>`gpt4all:wizardlm-13b-v1.2.Q4_0`</li><li>`gpt4all:nous-hermes-llama2-13b.Q4_0`</li><li>`gpt4all:gpt4all-13b-snoozy-q4_0`</li><li>`gpt4all:mpt-7b-chat-merges-q4_0`</li><li>`gpt4all:orca-mini-3b-gguf2-q4_0`</li><li>`gpt4all:starcoder-q4_0`</li><li>`gpt4all:rift-coder-v0-7b-q4_0`</li><li>`gpt4all:em_german_mistral_v01.Q4_0`</li></ul> |\n",
       "| `huggingface_hub` | `HUGGINGFACEHUB_API_TOKEN` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`. |\n",
       "| `mistralai` | `MISTRAL_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`mistralai:open-mistral-7b`</li><li>`mistralai:open-mixtral-8x7b`</li><li>`mistralai:open-mixtral-8x22b`</li><li>`mistralai:mistral-small-latest`</li><li>`mistralai:mistral-medium-latest`</li><li>`mistralai:mistral-large-latest`</li><li>`mistralai:codestral-latest`</li></ul> |\n",
       "| `nvidia-chat` | `NVIDIA_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`nvidia-chat:playground_llama2_70b`</li><li>`nvidia-chat:playground_nemotron_steerlm_8b`</li><li>`nvidia-chat:playground_mistral_7b`</li><li>`nvidia-chat:playground_nv_llama2_rlhf_70b`</li><li>`nvidia-chat:playground_llama2_13b`</li><li>`nvidia-chat:playground_steerlm_llama_70b`</li><li>`nvidia-chat:playground_llama2_code_13b`</li><li>`nvidia-chat:playground_yi_34b`</li><li>`nvidia-chat:playground_mixtral_8x7b`</li><li>`nvidia-chat:playground_neva_22b`</li><li>`nvidia-chat:playground_llama2_code_34b`</li></ul> |\n",
       "| `ollama` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | See [https://www.ollama.com/library](https://www.ollama.com/library) for a list of models. Pass a model's name; for example, `deepseek-coder-v2`. |\n",
       "| `openai` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai:babbage-002`</li><li>`openai:davinci-002`</li><li>`openai:gpt-3.5-turbo-instruct`</li></ul> |\n",
       "| `openai-chat` | `OPENAI_API_KEY` | <abbr title=\"You have set this environment variable, so you can use this provider's models.\">✅</abbr> | <ul><li>`openai-chat:gpt-3.5-turbo`</li><li>`openai-chat:gpt-3.5-turbo-0125`</li><li>`openai-chat:gpt-3.5-turbo-0301`</li><li>`openai-chat:gpt-3.5-turbo-0613`</li><li>`openai-chat:gpt-3.5-turbo-1106`</li><li>`openai-chat:gpt-3.5-turbo-16k`</li><li>`openai-chat:gpt-3.5-turbo-16k-0613`</li><li>`openai-chat:gpt-4`</li><li>`openai-chat:gpt-4-turbo`</li><li>`openai-chat:gpt-4-turbo-preview`</li><li>`openai-chat:gpt-4-0613`</li><li>`openai-chat:gpt-4-32k`</li><li>`openai-chat:gpt-4-32k-0613`</li><li>`openai-chat:gpt-4-0125-preview`</li><li>`openai-chat:gpt-4-1106-preview`</li><li>`openai-chat:gpt-4o`</li><li>`openai-chat:gpt-4o-mini`</li></ul> |\n",
       "| `openrouter` | `OPENROUTER_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | This provider does not define a list of models. |\n",
       "| `qianfan` | `QIANFAN_AK`, `QIANFAN_SK` | <abbr title=\"You have not set all of these environment variables, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`qianfan:ERNIE-Bot`</li><li>`qianfan:ERNIE-Bot-4`</li></ul> |\n",
       "| `sagemaker-endpoint` | Not applicable. | <abbr title=\"Not applicable\">N/A</abbr> | Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deploy-models.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints). |\n",
       "| `togetherai` | `TOGETHER_API_KEY` | <abbr title=\"You have not set this environment variable, so you cannot use this provider's models.\">❌</abbr> | <ul><li>`togetherai:Austism/chronos-hermes-13b`</li><li>`togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2`</li><li>`togetherai:EleutherAI/llemma_7b`</li><li>`togetherai:Gryphe/MythoMax-L2-13b`</li><li>`togetherai:Meta-Llama/Llama-Guard-7b`</li><li>`togetherai:Nexusflow/NexusRaven-V2-13B`</li><li>`togetherai:NousResearch/Nous-Capybara-7B-V1p9`</li><li>`togetherai:NousResearch/Nous-Hermes-2-Yi-34B`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-13b`</li><li>`togetherai:NousResearch/Nous-Hermes-Llama2-70b`</li></ul> |\n",
       "\n",
       "Aliases and custom commands:\n",
       "\n",
       "| Name | Target |\n",
       "|------|--------|\n",
       "| `gpt2` | `huggingface_hub:gpt2` |\n",
       "| `gpt3` | `openai:davinci-002` |\n",
       "| `chatgpt` | `openai-chat:gpt-3.5-turbo` |\n",
       "| `gpt4` | `openai-chat:gpt-4` |\n",
       "| `ernie-bot` | `qianfan:ERNIE-Bot` |\n",
       "| `ernie-bot-4` | `qianfan:ERNIE-Bot-4` |\n",
       "| `titan` | `bedrock:amazon.titan-tg1-large` |\n",
       "| `openrouter-claude` | `openrouter:anthropic/claude-3.5-sonnet:beta` |\n"
      ],
      "text/plain": [
       "ai21\n",
       "Requires environment variable: AI21_API_KEY (not set)\n",
       "* ai21:j1-large\n",
       "* ai21:j1-grande\n",
       "* ai21:j1-jumbo\n",
       "* ai21:j1-grande-instruct\n",
       "* ai21:j2-large\n",
       "* ai21:j2-grande\n",
       "* ai21:j2-jumbo\n",
       "* ai21:j2-grande-instruct\n",
       "* ai21:j2-jumbo-instruct\n",
       "\n",
       "bedrock\n",
       "* bedrock:amazon.titan-text-express-v1\n",
       "* bedrock:amazon.titan-text-lite-v1\n",
       "* bedrock:amazon.titan-text-premier-v1:0\n",
       "* bedrock:ai21.j2-ultra-v1\n",
       "* bedrock:ai21.j2-mid-v1\n",
       "* bedrock:ai21.jamba-instruct-v1:0\n",
       "* bedrock:cohere.command-light-text-v14\n",
       "* bedrock:cohere.command-text-v14\n",
       "* bedrock:cohere.command-r-v1:0\n",
       "* bedrock:cohere.command-r-plus-v1:0\n",
       "* bedrock:meta.llama2-13b-chat-v1\n",
       "* bedrock:meta.llama2-70b-chat-v1\n",
       "* bedrock:meta.llama3-8b-instruct-v1:0\n",
       "* bedrock:meta.llama3-70b-instruct-v1:0\n",
       "* bedrock:meta.llama3-1-8b-instruct-v1:0\n",
       "* bedrock:meta.llama3-1-70b-instruct-v1:0\n",
       "* bedrock:meta.llama3-1-405b-instruct-v1:0\n",
       "* bedrock:mistral.mistral-7b-instruct-v0:2\n",
       "* bedrock:mistral.mixtral-8x7b-instruct-v0:1\n",
       "* bedrock:mistral.mistral-large-2402-v1:0\n",
       "* bedrock:mistral.mistral-large-2407-v1:0\n",
       "\n",
       "bedrock-chat\n",
       "* bedrock-chat:amazon.titan-text-express-v1\n",
       "* bedrock-chat:amazon.titan-text-lite-v1\n",
       "* bedrock-chat:amazon.titan-text-premier-v1:0\n",
       "* bedrock-chat:anthropic.claude-v2\n",
       "* bedrock-chat:anthropic.claude-v2:1\n",
       "* bedrock-chat:anthropic.claude-instant-v1\n",
       "* bedrock-chat:anthropic.claude-3-sonnet-20240229-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-haiku-20240307-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-opus-20240229-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-5-haiku-20241022-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-5-sonnet-20240620-v1:0\n",
       "* bedrock-chat:anthropic.claude-3-5-sonnet-20241022-v2:0\n",
       "* bedrock-chat:meta.llama2-13b-chat-v1\n",
       "* bedrock-chat:meta.llama2-70b-chat-v1\n",
       "* bedrock-chat:meta.llama3-8b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-70b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-1-8b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-1-70b-instruct-v1:0\n",
       "* bedrock-chat:meta.llama3-1-405b-instruct-v1:0\n",
       "* bedrock-chat:mistral.mistral-7b-instruct-v0:2\n",
       "* bedrock-chat:mistral.mixtral-8x7b-instruct-v0:1\n",
       "* bedrock-chat:mistral.mistral-large-2402-v1:0\n",
       "* bedrock-chat:mistral.mistral-large-2407-v1:0\n",
       "\n",
       "bedrock-custom\n",
       "* Specify the ARN (Amazon Resource Name) of the custom/provisioned model as the model ID. For more information, see the [Amazon Bedrock model IDs documentation](https://docs.aws.amazon.com/bedrock/latest/userguide/model-ids.html).\n",
       "\n",
       "The model provider must also be specified below. This is the provider of your foundation model *in lowercase*, e.g. `amazon`, `anthropic`, `meta`, or `mistral`.\n",
       "\n",
       "anthropic-chat\n",
       "Requires environment variable: ANTHROPIC_API_KEY (not set)\n",
       "* anthropic-chat:claude-2.0\n",
       "* anthropic-chat:claude-2.1\n",
       "* anthropic-chat:claude-3-opus-20240229\n",
       "* anthropic-chat:claude-3-sonnet-20240229\n",
       "* anthropic-chat:claude-3-haiku-20240307\n",
       "* anthropic-chat:claude-3-5-haiku-20241022\n",
       "* anthropic-chat:claude-3-5-sonnet-20240620\n",
       "* anthropic-chat:claude-3-5-sonnet-20241022\n",
       "\n",
       "azure-chat-openai\n",
       "Requires environment variable: AZURE_OPENAI_API_KEY (not set)\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "cohere\n",
       "Requires environment variable: COHERE_API_KEY (not set)\n",
       "* cohere:command\n",
       "* cohere:command-nightly\n",
       "* cohere:command-light\n",
       "* cohere:command-light-nightly\n",
       "* cohere:command-r-plus\n",
       "* cohere:command-r\n",
       "\n",
       "gemini\n",
       "Requires environment variable: GOOGLE_API_KEY (not set)\n",
       "* gemini:gemini-1.5-pro\n",
       "* gemini:gemini-1.5-flash\n",
       "* gemini:gemini-1.0-pro\n",
       "* gemini:gemini-1.0-pro-001\n",
       "* gemini:gemini-1.0-pro-latest\n",
       "* gemini:gemini-1.0-pro-vision-latest\n",
       "* gemini:gemini-pro\n",
       "* gemini:gemini-pro-vision\n",
       "\n",
       "gpt4all\n",
       "* gpt4all:ggml-gpt4all-j-v1.2-jazzy\n",
       "* gpt4all:ggml-gpt4all-j-v1.3-groovy\n",
       "* gpt4all:ggml-gpt4all-l13b-snoozy\n",
       "* gpt4all:mistral-7b-openorca.Q4_0\n",
       "* gpt4all:mistral-7b-instruct-v0.1.Q4_0\n",
       "* gpt4all:gpt4all-falcon-q4_0\n",
       "* gpt4all:wizardlm-13b-v1.2.Q4_0\n",
       "* gpt4all:nous-hermes-llama2-13b.Q4_0\n",
       "* gpt4all:gpt4all-13b-snoozy-q4_0\n",
       "* gpt4all:mpt-7b-chat-merges-q4_0\n",
       "* gpt4all:orca-mini-3b-gguf2-q4_0\n",
       "* gpt4all:starcoder-q4_0\n",
       "* gpt4all:rift-coder-v0-7b-q4_0\n",
       "* gpt4all:em_german_mistral_v01.Q4_0\n",
       "\n",
       "huggingface_hub\n",
       "Requires environment variable: HUGGINGFACEHUB_API_TOKEN (not set)\n",
       "* See [https://huggingface.co/models](https://huggingface.co/models) for a list of models. Pass a model's repository ID as the model ID; for example, `huggingface_hub:ExampleOwner/example-model`.\n",
       "\n",
       "mistralai\n",
       "Requires environment variable: MISTRAL_API_KEY (not set)\n",
       "* mistralai:open-mistral-7b\n",
       "* mistralai:open-mixtral-8x7b\n",
       "* mistralai:open-mixtral-8x22b\n",
       "* mistralai:mistral-small-latest\n",
       "* mistralai:mistral-medium-latest\n",
       "* mistralai:mistral-large-latest\n",
       "* mistralai:codestral-latest\n",
       "\n",
       "nvidia-chat\n",
       "Requires environment variable: NVIDIA_API_KEY (not set)\n",
       "* nvidia-chat:playground_llama2_70b\n",
       "* nvidia-chat:playground_nemotron_steerlm_8b\n",
       "* nvidia-chat:playground_mistral_7b\n",
       "* nvidia-chat:playground_nv_llama2_rlhf_70b\n",
       "* nvidia-chat:playground_llama2_13b\n",
       "* nvidia-chat:playground_steerlm_llama_70b\n",
       "* nvidia-chat:playground_llama2_code_13b\n",
       "* nvidia-chat:playground_yi_34b\n",
       "* nvidia-chat:playground_mixtral_8x7b\n",
       "* nvidia-chat:playground_neva_22b\n",
       "* nvidia-chat:playground_llama2_code_34b\n",
       "\n",
       "ollama\n",
       "* See [https://www.ollama.com/library](https://www.ollama.com/library) for a list of models. Pass a model's name; for example, `deepseek-coder-v2`.\n",
       "\n",
       "openai\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai:babbage-002\n",
       "* openai:davinci-002\n",
       "* openai:gpt-3.5-turbo-instruct\n",
       "\n",
       "openai-chat\n",
       "Requires environment variable: OPENAI_API_KEY (set)\n",
       "* openai-chat:gpt-3.5-turbo\n",
       "* openai-chat:gpt-3.5-turbo-0125\n",
       "* openai-chat:gpt-3.5-turbo-0301\n",
       "* openai-chat:gpt-3.5-turbo-0613\n",
       "* openai-chat:gpt-3.5-turbo-1106\n",
       "* openai-chat:gpt-3.5-turbo-16k\n",
       "* openai-chat:gpt-3.5-turbo-16k-0613\n",
       "* openai-chat:gpt-4\n",
       "* openai-chat:gpt-4-turbo\n",
       "* openai-chat:gpt-4-turbo-preview\n",
       "* openai-chat:gpt-4-0613\n",
       "* openai-chat:gpt-4-32k\n",
       "* openai-chat:gpt-4-32k-0613\n",
       "* openai-chat:gpt-4-0125-preview\n",
       "* openai-chat:gpt-4-1106-preview\n",
       "* openai-chat:gpt-4o\n",
       "* openai-chat:gpt-4o-mini\n",
       "\n",
       "openrouter\n",
       "Requires environment variable: OPENROUTER_API_KEY (not set)\n",
       "* This provider does not define a list of models.\n",
       "\n",
       "qianfan\n",
       "Requires environment variables: QIANFAN_AK (not set), QIANFAN_SK (not set)\n",
       "* qianfan:ERNIE-Bot\n",
       "* qianfan:ERNIE-Bot-4\n",
       "\n",
       "sagemaker-endpoint\n",
       "* Specify an endpoint name as the model ID. In addition, you must specify a region name, request schema, and response path. For more information, see the documentation about [SageMaker endpoints deployment](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints-deploy-models.html) and about [using magic commands with SageMaker endpoints](https://jupyter-ai.readthedocs.io/en/latest/users/index.html#using-magic-commands-with-sagemaker-endpoints).\n",
       "\n",
       "togetherai\n",
       "Requires environment variable: TOGETHER_API_KEY (not set)\n",
       "* togetherai:Austism/chronos-hermes-13b\n",
       "* togetherai:DiscoResearch/DiscoLM-mixtral-8x7b-v2\n",
       "* togetherai:EleutherAI/llemma_7b\n",
       "* togetherai:Gryphe/MythoMax-L2-13b\n",
       "* togetherai:Meta-Llama/Llama-Guard-7b\n",
       "* togetherai:Nexusflow/NexusRaven-V2-13B\n",
       "* togetherai:NousResearch/Nous-Capybara-7B-V1p9\n",
       "* togetherai:NousResearch/Nous-Hermes-2-Yi-34B\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-13b\n",
       "* togetherai:NousResearch/Nous-Hermes-Llama2-70b\n",
       "\n",
       "\n",
       "Aliases and custom commands:\n",
       "gpt2 - huggingface_hub:gpt2\n",
       "gpt3 - openai:davinci-002\n",
       "chatgpt - openai-chat:gpt-3.5-turbo\n",
       "gpt4 - openai-chat:gpt-4\n",
       "ernie-bot - qianfan:ERNIE-Bot\n",
       "ernie-bot-4 - qianfan:ERNIE-Bot-4\n",
       "titan - bedrock:amazon.titan-tg1-large\n",
       "openrouter-claude - openrouter:anthropic/claude-3.5-sonnet:beta\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%ai list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f8aee8eb-b2d2-4e0e-a171-e71dea311393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Aspect     | System | User    | Assistant |\n",
       "|------------|--------|---------|-----------|\n",
       "| Role       | Executes predefined tasks and functions | Provides input, sets preferences, initiates requests | Offers guidance, answers questions, performs tasks based on user input |\n",
       "| Interaction | Minimal direct interaction with user | Directly interacts with system, inputs data, makes decisions | Receives and processes user input, provides feedback and assistance |\n",
       "| Decision-making | Follows predefined algorithms and rules | Makes decisions based on user input and preferences | Uses AI algorithms to provide responses and perform tasks |\n",
       "| Customization | Limited customization options | Can customize settings and preferences | Adapts to user preferences and behavior, offers personalized recommendations |\n",
       "| Autonomy    | Operates independently of user input | Relies on user input and guidance | Acts autonomously based on user input and system capabilities |\n",
       "| Learning    | Limited or no learning capabilities | Learns from user input and behavior | Utilizes machine learning to improve performance over time |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "system vs user vs assistant in ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4b05604-ed45-415c-b255-856900a4f8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "| Element | Calculation                       | Logic Explanation                            |\n",
       "|---------|-----------------------------------|----------------------------------------------|\n",
       "| 1       | 1                                 | Initial value                                |\n",
       "| 1       | 1                                 | Add the previous element (1) to get the next value |\n",
       "| 2       | 1 + 1 = 2                         | Add the previous element (1) to get the next value |\n",
       "| 4       | 2 + 2 = 4                         | Add the previous element (2) to get the next value |\n",
       "| 7       | 4 + 3 = 7                         | Add the previous element (4) to get the next value |\n",
       "| 11      | 7 + 4 = 11                        | Add the previous element (7) to get the next value |\n",
       "| 16      | 11 + 5 = 16                       | Add the previous element (11) to get the next value |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "gpt-3.5-turbo",
        "provider_id": "openai-chat"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai chatgpt\n",
    "explain the pattern [1, 1, 2, 4, 7, 11, 16]\n",
    "apply your logic to each element and show that it works"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
